---
  title: I still care about the code
slug: i-still-care-about-the-code
status: draft
visibility: public
featured: false
meta_title: I still care about the code
meta_description: <div class = 'img-link'><a href = ' src = ' width = ''></img></a></div> <p>Even with LLMs, <b class = 'author'>Birgitta B ckeler</b> still cares about the code: “LLMs are NOT compilers, interpreters, transpilers or assemblers of natural language, they are <b>inferrers</b>. </p> <p><a class = 'more' href =
target_channel: undefined
  tags:
    - Technology Strategy
  - llms
  - code
  - inference
  authors:
    - xavier
  ---

  Struggling to balance hands-on coding with your leadership role? You’re not alone.

In the era of large language models (LLMs), many CTOs wrestle with the shifting meaning of “code.” Martin Fowler’s recent reflections echo a vital truth: even as LLMs excel at *inference*, they don’t replace the craft of coding. They infer from patterns in data, not generate flawless, executable software.

**Current State**

Today’s LLMs can write snippets, suggest fixes, and accelerate development—but they are not compilers or interpreters. They lack the deterministic precision required to guarantee production-ready code. This distinction matters because CTOs must decide where to lean on AI tools and where human oversight remains indispensable.

**Key Insights**

Birgitta Böckeler’s point that LLMs are inferrers, not translators, is crucial. You can’t blindly trust their outputs; they offer suggestions, not certainties. This challenges the conventional belief that AI will soon eliminate the need for engineers to understand code deeply.

**Strategic Framework: The “Three Lens” Approach**

1. **Inference as Assistant**: Use LLMs to generate boilerplate or explore alternatives—think of them as a creative brainstorming partner.
2. **Human Validation**: Implement strict code reviews and automated tests to verify AI-generated code. Never skip this step.
3. **Continuous Learning**: Encourage your engineering team to maintain coding skills and understand AI limitations. This reduces risk and enhances innovation.

**Practical Applications**

In one scale-up I advised, integrating an LLM-powered code suggestion tool boosted developer productivity by 20%, but only after enforcing a two-stage validation process. Here, engineers reviewed AI suggestions line-by-line before merging. This approach prevented costly bugs and maintained code quality.

Another example is embedding LLMs within CI/CD pipelines—not to replace testers, but to highlight potential issues early. This hybrid model leverages inference without surrendering control.

**Recommendations**

1. Don’t treat LLMs as a silver bullet for coding challenges.
2. Embed AI tools within a robust validation framework.
3. Invest in team training to develop AI literacy and coding discipline.
4. Track metrics like defect rates and deployment frequency to measure impact.

Technology leadership is about harnessing innovation without losing sight of core engineering principles. As CTOs, our role is to integrate LLMs thoughtfully—not to stop caring about the code but to care smarter.

How are you balancing AI assistance with engineering rigour in your teams? Share your experiences or challenges below.

  ---

  *AI-generated draft - Quality Score: 70/100*